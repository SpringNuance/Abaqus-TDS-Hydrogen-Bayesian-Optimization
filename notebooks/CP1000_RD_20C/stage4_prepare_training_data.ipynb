{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current directory is: \n",
      "c:\\Users\\springnuance\\Desktop\\Abaqus-Hardening-Seq-2-Seq-Project\\notebooks\\CP1000_RD_20C\n",
      "The current directory is: \n",
      "c:\\Users\\springnuance\\Desktop\\Abaqus-Hardening-Seq-2-Seq-Project\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import os\n",
    "from math import * \n",
    "import torch\n",
    "\n",
    "print(\"The current directory is: \")\n",
    "print(os.getcwd())\n",
    "if not os.getcwd().endswith(\"Abaqus-Hardening-Seq-2-Seq-Project\"):\n",
    "    # Move up two directories\n",
    "    path_parent = os.path.dirname(os.getcwd())\n",
    "    os.chdir(path_parent)\n",
    "    path_parent = os.path.dirname(os.getcwd())\n",
    "    os.chdir(path_parent)\n",
    "print(\"The current directory is: \")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================\n",
      "= Stage 1: Loading configs and all paths =\n",
      "==========================================\n",
      "\n",
      "Welcome to Abaqus Seq2Seq flow curve calibration project\n",
      "\n",
      "The configurations you have chosen: \n",
      "\n",
      "+--------------------------+------------------------------------------------------------------+\n",
      "|      Global Configs      |                           User choice                            |\n",
      "+--------------------------+------------------------------------------------------------------+\n",
      "|         PROJECT          |                          CP1000_RD_20C                           |\n",
      "|        OBJECTIVES        |        CHD2, CHD4, NDBR2p5, NDBR6, NDBR15, NDBR40, SH115         |\n",
      "|       PROJECT_PATH       | c:\\Users\\springnuance\\Desktop\\Abaqus-Hardening-Seq-2-Seq-Project |\n",
      "|    TRAINING_DATA_PATH    |                   training_data/CP1000_RD_20C                    |\n",
      "|         LOG_PATH         |                      log/CP1000_RD_20C.txt                       |\n",
      "|       MODELS_PATH        |                       models/CP1000_RD_20C                       |\n",
      "|  RESULTS_INIT_DATA_PATH  |                results_initial_data/CP1000_RD_20C                |\n",
      "| RESULTS_INIT_COMMON_PATH |               results_initial_common/CP1000_RD_20C               |\n",
      "|  RESULTS_ITER_DATA_PATH  |               results_iteration_data/CP1000_RD_20C               |\n",
      "| RESULTS_ITER_COMMON_PATH |              results_iteration_common/CP1000_RD_20C              |\n",
      "|       SCRIPTS_PATH       |                      scripts/CP1000_RD_20C                       |\n",
      "|      SIMS_INIT_PATH      |                    sims_initial/CP1000_RD_20C                    |\n",
      "|      SIMS_ITER_PATH      |                   sims_iteration/CP1000_RD_20C                   |\n",
      "|       TARGETS_PATH       |                      targets/CP1000_RD_20C                       |\n",
      "|      TEMPLATES_PATH      |                     templates/CP1000_RD_20C                      |\n",
      "+--------------------------+------------------------------------------------------------------+\n",
      "\n",
      "The path to your main project folder is\n",
      "\n",
      "c:\\Users\\springnuance\\Desktop\\Abaqus-Hardening-Seq-2-Seq-Project\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from configs.chosen_project import *\n",
    "from src.stage1_global_configs import *\n",
    "\n",
    "chosen_project_path = \"configs/global_config_CP1000_RD_20C.json\"\n",
    "\n",
    "global_configs = main_global_configs(chosen_project_path)\n",
    "\n",
    "all_paths = global_configs['all_paths']\n",
    "objectives = global_configs['objectives']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this stage, we construct the torch tensors from the FD curves, the flow curves for both simulation and the experimental FD curves. \n",
    "\n",
    "source_sequences is of shape (num_samples, source_len, num_objectives). It is the combination of FD curve. Later, num_samples would be the batch_size\n",
    "\n",
    "target_sequences is of shape (num_samples, target_len, 1). All FD curves share one single flow curve. Later num_samples would be the batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The source sequence is constructed with shape (num_sims, source_len, num_objectives):\n",
      "torch.Size([256, 100, 7])\n"
     ]
    }
   ],
   "source": [
    "results_init_common_path = all_paths[\"results_init_common_path\"]\n",
    "training_data_path = all_paths[\"training_data_path\"]\n",
    "targets_path = all_paths[\"targets_path\"]\n",
    "\n",
    "model_config = global_configs[\"model_config\"]\n",
    "\n",
    "interpolated_displacement_len = global_configs[\"interpolated_displacement_len\"]\n",
    "\n",
    "source_sequence = []\n",
    "\n",
    "for i, objective in enumerate(objectives):\n",
    "    source_sequence_one_sim = []\n",
    "    if os.path.exists(f\"{results_init_common_path}/{objective}/FD_curves_interpolated.npy\"):\n",
    "        # Plotting the mean simulated FD curve\n",
    "        FD_curves_interpolated = np.load(f\"{results_init_common_path}/{objective}/FD_curves_interpolated.npy\", allow_pickle=True).tolist()\n",
    "        for params_tuple, FD_curve_interpolated in FD_curves_interpolated.items():\n",
    "            sim_force_interpolated = FD_curve_interpolated['force']\n",
    "            source_sequence_one_sim.append(sim_force_interpolated)\n",
    "        source_sequence.append(source_sequence_one_sim)\n",
    "\n",
    "source_sequence = np.array(source_sequence)\n",
    "# Convert to tensor\n",
    "source_sequence = torch.tensor(source_sequence)\n",
    "source_sequence = source_sequence.permute(1, 2, 0)\n",
    "print(\"The source sequence is constructed with shape (num_sims, source_len, num_objectives):\")\n",
    "print(source_sequence.shape)\n",
    "            \n",
    "# Now we need to verify if this source sequence is constructed correctly\n",
    "\n",
    "for i, objective in enumerate(objectives):\n",
    "    \n",
    "    if os.path.exists(f\"{results_init_common_path}/{objective}/FD_curves_interpolated.npy\"):\n",
    "        # Plotting the mean simulated FD curve\n",
    "        FD_curves_interpolated = np.load(f\"{results_init_common_path}/{objective}/FD_curves_interpolated.npy\", allow_pickle=True).tolist()\n",
    "        for sim_index, (params_tuple, FD_curve_interpolated) in enumerate(FD_curves_interpolated.items()):\n",
    "            sim_force_interpolated = FD_curve_interpolated['force']\n",
    "            sim_force_interpolated = torch.tensor(sim_force_interpolated)\n",
    "            assert torch.allclose(source_sequence[sim_index, :, i], sim_force_interpolated)\n",
    "    \n",
    "# Now we save the source sequence\n",
    "torch.save(source_sequence, f\"{training_data_path}/initial_source_sequence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sequence is constructed with shape (num_sims, target_len, 1):\n",
      "torch.Size([256, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "### Now we construct the target sequence\n",
    "\n",
    "target_sequence = []\n",
    "\n",
    "if os.path.exists(f\"{results_init_common_path}/initial_sampled_true_stress.npy\"):\n",
    "\n",
    "    initial_sampled_true_stress = np.load(f\"{results_init_common_path}/initial_sampled_true_stress.npy\", allow_pickle=True).tolist()\n",
    "    target_sequence = torch.tensor(initial_sampled_true_stress)\n",
    "\n",
    "# turn it into (num_sims, target_len, 1)\n",
    "target_sequence = target_sequence.unsqueeze(-1)\n",
    "print(\"The target sequence is constructed with shape (num_sims, target_len, 1):\")\n",
    "print(target_sequence.shape)\n",
    "\n",
    "# Now we save the target sequence\n",
    "# target length totally depends on true_plastic_strain_config, we should not interpolate them\n",
    "\n",
    "torch.save(target_sequence, f\"{training_data_path}/initial_target_sequence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exp_source_sequence is constructed with shape (1, source_len, num_objectives):\n",
      "torch.Size([1, 100, 7])\n"
     ]
    }
   ],
   "source": [
    "# Now we construct the exp_source_sequence, which is used the prediction of flow curve\n",
    "# There is only 1 experimental data so it should have shape (1, source_len, num_objectives)\n",
    "\n",
    "targets_path = all_paths[\"targets_path\"]\n",
    "exp_source_sequence = []\n",
    "\n",
    "for i, objective in enumerate(objectives):\n",
    "    FD_curve_final_interpolated = pd.read_excel(f\"{targets_path}/{objective}/FD_curve_final_interpolated.xlsx\", engine='openpyxl')\n",
    "    exp_force_interpolated = FD_curve_final_interpolated['force/N'].values\n",
    "    exp_source_sequence.append(exp_force_interpolated)\n",
    "\n",
    "# Convert to tensor\n",
    "exp_source_sequence = torch.tensor(exp_source_sequence).permute(1,0)\n",
    "exp_source_sequence = exp_source_sequence.unsqueeze(0)\n",
    "print(\"The exp_source_sequence is constructed with shape (1, source_len, num_objectives):\")\n",
    "print(exp_source_sequence.shape)\n",
    "\n",
    "# Verify if this exp_source_sequence is constructed correctly\n",
    "for i, objective in enumerate(objectives):\n",
    "    FD_curve_final_interpolated = pd.read_excel(f\"{targets_path}/{objective}/FD_curve_final_interpolated.xlsx\", engine='openpyxl')\n",
    "    exp_force_interpolated = FD_curve_final_interpolated['force/N'].values\n",
    "    exp_force_interpolated = torch.tensor(exp_force_interpolated)\n",
    "    assert torch.allclose(exp_source_sequence[0, :, i], exp_force_interpolated)\n",
    "    \n",
    "# Now we save the exp_source_sequence\n",
    "torch.save(exp_source_sequence, f\"{training_data_path}/exp_source_sequence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training and testing source and target sequences are constructed with shapes:\n",
      "train_source_sequence shape: torch.Size([192, 100, 7])\n",
      "train_target_sequence shape: torch.Size([192, 100, 1])\n",
      "test_source_sequence shape: torch.Size([64, 100, 7])\n",
      "test_target_sequence shape: torch.Size([64, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "initial_test_ratio = model_config[\"initial_test_ratio\"]\n",
    "\n",
    "# Now we split the source_sequence, target_sequence and exp_source_sequence into training and testing\n",
    "# There is no randomization\n",
    "num_sims = source_sequence.shape[0]\n",
    "\n",
    "num_test_sims = ceil(num_sims * initial_test_ratio)\n",
    "num_train_sims = num_sims - num_test_sims\n",
    "\n",
    "train_source_sequence = source_sequence[:num_train_sims]\n",
    "train_target_sequence = target_sequence[:num_train_sims]\n",
    "test_source_sequence = source_sequence[num_train_sims:]\n",
    "test_target_sequence = target_sequence[num_train_sims:]\n",
    "\n",
    "print(\"The training and testing source and target sequences are constructed with shapes:\")\n",
    "print(\"train_source_sequence shape:\", train_source_sequence.shape)\n",
    "print(\"train_target_sequence shape:\", train_target_sequence.shape)\n",
    "print(\"test_source_sequence shape:\", test_source_sequence.shape)\n",
    "print(\"test_target_sequence shape:\", test_target_sequence.shape)\n",
    "\n",
    "torch.save(train_source_sequence, f\"{training_data_path}/initial_train_source_sequence.pt\")\n",
    "torch.save(train_target_sequence, f\"{training_data_path}/initial_train_target_sequence.pt\")\n",
    "torch.save(test_source_sequence, f\"{training_data_path}/initial_test_source_sequence.pt\")\n",
    "torch.save(test_target_sequence, f\"{training_data_path}/initial_test_target_sequence.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### However, due to the nature of the flow curve, which is always monotonically increasing, using the flow curve as the target sequence would not be a good idea. Instead, we use the derivative of the flow curve as the target sequence. To be compatible, the FD curves are also differentiated. \n",
    "\n",
    "The differentiation is simply done by subtracting the current value from the next value, reducing the length of the sequence by 1. When training the Seq2Seq models, we can use a ReLU activation function to ensure the target sequence is always positive, reflecting the positive incremental flow curve\n",
    "\n",
    "Question: how can we reconstruct the curves when we do not know the first value?\n",
    "\n",
    "We would train two separate models, one to learn the incremental change, and one to solely learn the first N values. This N values is \"divided_index\" from model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The divided index is: 0\n",
      "The training and testing source and target sequences are constructed with shapes:\n",
      "train_source_sequence_diff shape: torch.Size([192, 99, 7])\n",
      "train_target_sequence_diff shape: torch.Size([192, 99, 1])\n",
      "test_source_sequence_diff shape: torch.Size([64, 99, 7])\n",
      "test_target_sequence_diff shape: torch.Size([64, 99, 1])\n",
      "The training and testing source and target sequences are constructed with shapes:\n",
      "train_source_sequence_first shape: torch.Size([192, 1, 7])\n",
      "train_target_sequence_first shape: torch.Size([192, 1, 1])\n",
      "test_source_sequence_first shape: torch.Size([64, 1, 7])\n",
      "test_target_sequence_first shape: torch.Size([64, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "divided_index = model_config[\"divided_index\"]\n",
    "print(\"The divided index is:\", divided_index)\n",
    "\n",
    "train_source_sequence_diff = train_source_sequence[:, divided_index+1:, :] - train_source_sequence[:, divided_index:-1, :]\n",
    "train_target_sequence_diff = train_target_sequence[:, divided_index+1:, :] - train_target_sequence[:, divided_index:-1, :]\n",
    "test_source_sequence_diff = test_source_sequence[:, divided_index+1:, :] - test_source_sequence[:, divided_index:-1, :]\n",
    "test_target_sequence_diff = test_target_sequence[:, divided_index+1:, :] - test_target_sequence[:, divided_index:-1, :]\n",
    "\n",
    "print(\"The training and testing source and target sequences are constructed with shapes:\")\n",
    "print(\"train_source_sequence_diff shape:\", train_source_sequence_diff.shape)\n",
    "print(\"train_target_sequence_diff shape:\", train_target_sequence_diff.shape)\n",
    "print(\"test_source_sequence_diff shape:\", test_source_sequence_diff.shape)\n",
    "print(\"test_target_sequence_diff shape:\", test_target_sequence_diff.shape)\n",
    "\n",
    "torch.save(train_source_sequence_diff, f\"{training_data_path}/initial_train_source_sequence_diff.pt\")\n",
    "torch.save(train_target_sequence_diff, f\"{training_data_path}/initial_train_target_sequence_diff.pt\")\n",
    "torch.save(test_source_sequence_diff, f\"{training_data_path}/initial_test_source_sequence_diff.pt\")\n",
    "torch.save(test_target_sequence_diff, f\"{training_data_path}/initial_test_target_sequence_diff.pt\")\n",
    "\n",
    "train_source_sequence_first = train_source_sequence[:, :divided_index+1, :]\n",
    "train_target_sequence_first = train_target_sequence[:, :divided_index+1, :]\n",
    "test_source_sequence_first = test_source_sequence[:, :divided_index+1, :]\n",
    "test_target_sequence_first = test_target_sequence[:, :divided_index+1, :]\n",
    "\n",
    "print(\"The training and testing source and target sequences are constructed with shapes:\")\n",
    "print(\"train_source_sequence_first shape:\", train_source_sequence_first.shape)\n",
    "print(\"train_target_sequence_first shape:\", train_target_sequence_first.shape)\n",
    "print(\"test_source_sequence_first shape:\", test_source_sequence_first.shape)\n",
    "print(\"test_target_sequence_first shape:\", test_target_sequence_first.shape)\n",
    "\n",
    "torch.save(train_source_sequence_first, f\"{training_data_path}/initial_train_source_sequence_first.pt\")\n",
    "torch.save(train_target_sequence_first, f\"{training_data_path}/initial_train_target_sequence_first.pt\")\n",
    "torch.save(test_source_sequence_first, f\"{training_data_path}/initial_test_source_sequence_first.pt\")\n",
    "torch.save(test_target_sequence_first, f\"{training_data_path}/initial_test_target_sequence_first.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
